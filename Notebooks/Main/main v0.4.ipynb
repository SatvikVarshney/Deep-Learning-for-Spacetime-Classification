{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Satvik Varshney ; Waterloo ID: 20764052\n",
    "#### Phys 449 , Main Assignment\n",
    "#### Submission date : 06 Dec 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Necessary Libraries\n",
    "\n",
    "# Data read/write libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "\n",
    "# Data calculation and manipulation libraries\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#PyTorch Specific libraries\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "#plaotting the chart\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the petrov type determination Model \n",
    "class model_petrovtype_classification(nn.Module):\n",
    "    def __init__(self):   \n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_layer_1 = nn.Linear(num_input, num_hidden)  # 5,500\n",
    "        self.hidden_layer_2 = nn.Linear(num_hidden, num_hidden)   # 500,500\n",
    "        self.hidden_layer_3 = nn.Linear(num_hidden, num_hidden)   # 500,500\n",
    "        self.hidden_layer_4 = nn.Linear(num_hidden, num_hidden)   # 500,500\n",
    "        self.output_layer = nn.Linear(num_hidden, num_classes)   # 500, 6\n",
    "\n",
    "        # Reset the layers\n",
    "        self.hidden_layer_1.reset_parameters()\n",
    "        self.hidden_layer_2.reset_parameters()\n",
    "        self.hidden_layer_3.reset_parameters()\n",
    "        self.hidden_layer_4.reset_parameters()\n",
    "        self.output_layer.reset_parameters()\n",
    "        \n",
    "        self.activation_layer1 = nn.Tanh()\n",
    "        self.dropout_layer1 = nn.Dropout(p=0.2)\n",
    "        self.activation_layer2 = nn.Sigmoid()\n",
    "        self.dropout_layer2 = nn.Dropout(p=0.2)\n",
    "        self.activation_layer3 = nn.Tanh()\n",
    "        self.dropout_layer3 = nn.Dropout(p=0.2)\n",
    "        self.activation_layer4 = nn.Sigmoid()\n",
    "        self.dropout_layer4 = nn.Dropout(p=0.2)\n",
    "        self.activation_outputlayer = nn.Softmax(dim=1)\n",
    "\n",
    "        self.loss = nn.CrossEntropyLoss() # Loss used for multi variate analysis\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.hidden_layer_1(inputs)\n",
    "        x = self.activation_layer1(x)\n",
    "        x = self.dropout_layer1(x)\n",
    "        x = self.hidden_layer_2(x)\n",
    "        x = self.activation_layer2(x)\n",
    "        x = self.dropout_layer2(x)\n",
    "        x = self.hidden_layer_3(x)\n",
    "        x = self.activation_layer3(x)\n",
    "        x = self.dropout_layer3(x)\n",
    "        x = self.hidden_layer_4(x)\n",
    "        x = self.activation_layer4(x)\n",
    "        x = self.dropout_layer4(x)\n",
    "        x = self.output_layer(x)\n",
    "        x = self.activation_outputlayer(x)\n",
    "        return x\n",
    "\n",
    "    def fit(self, X,Y):\n",
    "        self.optimizer.zero_grad()\n",
    "        y_pred = self.forward(X)\n",
    "        loss = self.loss(y_pred, Y)\n",
    "        y_pred_max = torch.argmax(y_pred, axis=1)\n",
    "        train_accuracy = (Y == y_pred_max).sum()\n",
    "        loss.backward()   #backpropagation\n",
    "        self.optimizer.step()   # updating the weights\n",
    "        return loss.item(), train_accuracy\n",
    "\n",
    "    def evaluate(self,test_dataloader):\n",
    "        acc_test = 0\n",
    "        loss_test= 0\n",
    "        for X,Y in test_dataloader:\n",
    "            with torch.no_grad():\n",
    "                loss_temp = self.loss(self.forward(X.float()), Y.long())\n",
    "                # just to manage the error relted to numpy and tensor\n",
    "                loss_temp = loss_temp.detach().numpy()\n",
    "                loss_test += loss_temp\n",
    "                # to calculate the test accuracy\n",
    "                y_pred_test = torch.argmax(self.forward(X.float()), axis=1)\n",
    "                acc_test += (Y == y_pred_test).sum()   # batch\n",
    "\n",
    "        avg_acc_test = acc_test / (len(test_dataloader)* batch)\n",
    "        avg_loss_test = loss_test/len(test_dataloader)\n",
    "\n",
    "        return avg_acc_test ,avg_loss_test\n",
    "    \n",
    "    def determine_petrov(self,X):\n",
    "        with torch.no_grad():\n",
    "            y_pred_test= self.forward(X)\n",
    "            return torch.argmax(y_pred_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class class_data_tranformation:\n",
    "    def fn_convert_petrov_classification_data(self, y):\n",
    "        y_converted = []\n",
    "        for idx, y_val in enumerate(y):\n",
    "            if y_val == \"O\": y_converted.append(0)\n",
    "            elif y_val == \"I\": y_converted.append(1)\n",
    "            elif y_val == \"II\": y_converted.append(2)\n",
    "            elif y_val == \"III\": y_converted.append(3)\n",
    "            elif y_val == \"D\": y_converted.append(4)\n",
    "            elif y_val == \"N\": y_converted.append(5)\n",
    "        return y_converted\n",
    "\n",
    "    def fn_split_train_val_test(self, data):\n",
    "        # separate the last colums as y-data\n",
    "        Y = data[:,5] \n",
    "        X = np.delete(data, 5,1)  # Input data\n",
    "        y = np.array(self.fn_convert_petrov_classification_data(Y))\n",
    "        total_rows, total_cols = data.shape\n",
    "        testdata_rows = int(total_rows*30/100) # 30% test data\n",
    "        # separate the test data Last 30% records\n",
    "        x_test_temp = X[-testdata_rows:, :]\n",
    "        y_test_temp = y[-testdata_rows:]\n",
    "\n",
    "        # build the training data 70%\n",
    "        x_train  = X[:-len(x_test_temp), :] \n",
    "        y_train = y[:-len(y_test_temp)] \n",
    "\n",
    "        # separate 15% as validation data from Test data 15%\n",
    "        x_test = x_test_temp[-int(testdata_rows/2):, :]\n",
    "        y_test = y_test_temp[-int(testdata_rows/2):]\n",
    "\n",
    "        # build the validartion data 15%\n",
    "        x_val  = x_test_temp[:-len(x_test), :] \n",
    "        y_val = y_test_temp[:-len(y_test)] \n",
    "\n",
    "        # change the dtype to 'float64'\n",
    "        x_train = x_train.astype('float64')\n",
    "        x_test = x_test.astype('float64')  \n",
    "        x_val = x_val.astype('float64')   \n",
    "\n",
    "        return x_train, y_train, x_val, y_val, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 0:   0%|▎                                                               | 8/1882 [00:00<00:26, 71.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train unnormalized =  [[0. 0. 1. 1. 0.]\n",
      " [1. 1. 0. 0. 1.]\n",
      " [0. 0. 1. 1. 0.]]\n",
      "x_train normalized =  [[0. 0. 1. 1. 0.]\n",
      " [1. 1. 0. 0. 1.]\n",
      " [0. 0. 1. 1. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 0: 100%|█████████████████████████████████████████████████████████████| 1882/1882 [00:34<00:00, 54.03it/s]\n",
      "Fitting epoch 1:   0%|▏                                                               | 4/1882 [00:00<00:47, 39.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training Loss = : 1.3998 and Accuracy = : 0.6429\n",
      "Epoch 1 Validation Loss = : 1.3041 and Accuracy = : 0.7366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 1: 100%|█████████████████████████████████████████████████████████████| 1882/1882 [00:37<00:00, 50.54it/s]\n",
      "Fitting epoch 2:   0%|▏                                                               | 5/1882 [00:00<00:44, 42.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training Loss = : 1.2846 and Accuracy = : 0.7587\n",
      "Epoch 2 Validation Loss = : 1.2820 and Accuracy = : 0.7602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 2: 100%|█████████████████████████████████████████████████████████████| 1882/1882 [00:37<00:00, 50.51it/s]\n",
      "Fitting epoch 3:   0%|▏                                                               | 5/1882 [00:00<00:42, 44.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training Loss = : 1.2815 and Accuracy = : 0.7620\n",
      "Epoch 3 Validation Loss = : 1.2819 and Accuracy = : 0.7602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 3: 100%|█████████████████████████████████████████████████████████████| 1882/1882 [00:37<00:00, 50.36it/s]\n",
      "Fitting epoch 4:   0%|▏                                                               | 4/1882 [00:00<00:51, 36.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training Loss = : 1.2812 and Accuracy = : 0.7623\n",
      "Epoch 4 Validation Loss = : 1.2807 and Accuracy = : 0.7613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 4: 100%|█████████████████████████████████████████████████████████████| 1882/1882 [00:37<00:00, 49.87it/s]\n",
      "Fitting epoch 5:   0%|▏                                                               | 4/1882 [00:00<00:49, 37.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training Loss = : 1.2797 and Accuracy = : 0.7638\n",
      "Epoch 5 Validation Loss = : 1.2807 and Accuracy = : 0.7613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 5: 100%|█████████████████████████████████████████████████████████████| 1882/1882 [00:37<00:00, 50.43it/s]\n",
      "Fitting epoch 6:   0%|▏                                                               | 4/1882 [00:00<00:51, 36.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training Loss = : 1.2797 and Accuracy = : 0.7638\n",
      "Epoch 6 Validation Loss = : 1.2800 and Accuracy = : 0.7609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 6: 100%|█████████████████████████████████████████████████████████████| 1882/1882 [00:37<00:00, 50.34it/s]\n",
      "Fitting epoch 7:   0%|▏                                                               | 4/1882 [00:00<00:50, 36.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training Loss = : 1.2797 and Accuracy = : 0.7637\n",
      "Epoch 7 Validation Loss = : 1.2810 and Accuracy = : 0.7613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 7: 100%|█████████████████████████████████████████████████████████████| 1882/1882 [00:37<00:00, 50.37it/s]\n",
      "Fitting epoch 8:   0%|▏                                                               | 4/1882 [00:00<00:49, 38.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training Loss = : 1.2797 and Accuracy = : 0.7637\n",
      "Epoch 8 Validation Loss = : 1.2809 and Accuracy = : 0.7613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 8: 100%|█████████████████████████████████████████████████████████████| 1882/1882 [00:37<00:00, 50.43it/s]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    if sys.argv[1] == \"--help\":\n",
    "        print (\"Syntax = python main.py param/param_file_name.json petrov_data.csv performance.html\")\n",
    "        print (\"Parameter 1 = param/param_file_name.json \")\n",
    "        print (\"  Parameter 1 description = JSON file to keep the hyper parameters (e.g. learning rate, batch size, etc.)\")\n",
    "        print (\"  Parameter 1 default value = param/param_file_name.json\")\n",
    "        print (\"  Parameter 1 file type = JSON\")\n",
    "        print (\"Parameter 2 = even_mnist.csv \")\n",
    "        print (\"  Parameter 2 description = Petrov Input dataset file name with path\")\n",
    "        print (\"  Parameter 2 default value = even_mnist.csv\")\n",
    "        print (\"  Parameter 2 file type = csv\")\n",
    "        print (\"Parameter 3 = performance.html \")\n",
    "        print (\"  Parameter 3 description = html file name with path to record the output.This report summarizes the final results and performance.\")\n",
    "        print (\"  Parameter 3 default value = result/Performance.html\")\n",
    "        print (\"  Parameter 3 file type = html\")\n",
    "    else:\n",
    "        if len(sys.argv) == 4: \n",
    "            json_file = sys.argv[1] #param/param_file_name.json\n",
    "            dataset_url = sys.argv[2] #'even_mnist.csv'\n",
    "            outputfilename = sys.argv[3] # performance.html\n",
    "        else:\n",
    "            json_file = \"param/param_file_name.json\" \n",
    "            dataset_url = \"petrov_data.csv\"\n",
    "            outputfilename = \"result/Performance.html\"\n",
    "            \n",
    "        obj_dt = class_data_tranformation()\n",
    "        # reading csv file\n",
    "        df = pd.read_csv(dataset_url, sep=',', header=None)\n",
    "        data = df.to_numpy() # convert dataframe to array\n",
    "        x_train, y_train, x_val, y_val, x_test, y_test  = obj_dt.fn_split_train_val_test(data)\n",
    "\n",
    "        # Importing json file to read the parametes\n",
    "        f = open(json_file)\n",
    "        dt_json = json.load(f)\n",
    "        lr = dt_json['learning rate']\n",
    "        # specify input dimensions of each image\n",
    "        num_input = dt_json['num_input'] #5\n",
    "        # batch size, number of classes, epochs\n",
    "        batch = dt_json['batch_size']#128\n",
    "        num_classes = dt_json['num_classes']#6\n",
    "        epochs = dt_json['num iter']\n",
    "        num_hidden = dt_json['num_hidden']\n",
    "\n",
    "        # normalise datasets\n",
    "        x_train = (x_train - x_train.min()) / (x_train.max() - x_train.min())\n",
    "        x_test = (x_test - x_test.min()) / (x_test.max() - x_test.min())\n",
    "        x_val = (x_val - x_val.min()) / (x_val.max() - x_val.min())\n",
    "\n",
    "        #Converting to Tensors\n",
    "        X_train = torch.from_numpy(x_train)\n",
    "        X_test = torch.from_numpy(x_test)\n",
    "        X_val = torch.from_numpy(x_val)\n",
    "\n",
    "        y_train = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "        y_test = torch.from_numpy(y_test).type(torch.LongTensor)\n",
    "        y_val = torch.from_numpy(y_val).type(torch.LongTensor)\n",
    "\n",
    "        train = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "        test = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "        val = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "        # Set our data loaders into batches\n",
    "        train_loader = torch.utils.data.DataLoader(train, batch_size = batch, shuffle = True)\n",
    "        test_loader = torch.utils.data.DataLoader(test, batch_size = batch, shuffle = True)\n",
    "        val_loader = torch.utils.data.DataLoader(val, batch_size = batch, shuffle = True)\n",
    "\n",
    "        # Open output html file \n",
    "        outputfilename_sub = outputfilename[:len(outputfilename)-5]\n",
    "        objOutputFile = open(outputfilename,\"w\")\n",
    "        # Adding header data to the HTML file\n",
    "#        objOutputFile.write(\"<html>\\n<head><title bgcolor='#2980B9'> \\nPerformance Report \\</title></head> <body><h1>Physics 449 Main Assignment</h1><h2>Satvik Varshney</h2></body></html>\")\n",
    "        objOutputFile.write(\"<html>\\n<head><title bgcolor='#2980B9'> \\nPerformance Report \\</title></head> <body><h1>Physics 449 Main Assignment</h1></body></html>\")\n",
    "        objOutputFile.write(\"<table>\")\n",
    "        \n",
    "        #Building the Model\n",
    "        obj_model_petrov = model_petrovtype_classification().to(torch.device(\"cpu\"))\n",
    "\n",
    "        # Initialize the vectors for performance tracking and display for train and test dataset\n",
    "        train_val_loss = []\n",
    "        train_val_acc = []\n",
    "        validation_val_loss = []\n",
    "        validation_val_acc=[]\n",
    "\n",
    "        for i in range(epochs):\n",
    "            # Train the system\n",
    "            total_loss = 0\n",
    "            total_acc = 0\n",
    "            for X,Y in tqdm(train_loader, desc = f\"Fitting epoch {i}\"):\n",
    "                loss, acc = obj_model_petrov.fit(X.float(),Y.long())\n",
    "                total_loss += loss\n",
    "                total_acc +=acc\n",
    "            avg_loss = total_loss/len(train_loader)\n",
    "            avg_acc = total_acc / (len(train_loader)* batch)\n",
    "            train_val_loss.append(avg_loss)\n",
    "            train_val_acc.append(avg_acc)\n",
    "            # Evaluate the model\n",
    "            acc_test,loss_test = obj_model_petrov.evaluate(val_loader)\n",
    "            validation_val_loss.append(loss_test)\n",
    "            validation_val_acc.append(acc_test)\n",
    "            # Training, test data loss and accuray recording\n",
    "            training_performance_str = f\"Epoch {i+1} Training Loss = : {avg_loss:.4f} and Accuracy = : {avg_acc:.4f}\"\n",
    "            validation_performance_str = f\"Epoch {i+1} Validation Loss = : {loss_test:.4f} and Accuracy = : {acc_test:.4f}\"\n",
    "            # Pring Training and test data loss, accuray information to screen\n",
    "            print(training_performance_str)\n",
    "            print(validation_performance_str)\n",
    "            # Write Training and test data loss, accuray information to output html file\n",
    "            objOutputFile.write(\"<tr><td>\"+training_performance_str+\"</td></tr>\")\n",
    "            objOutputFile.write(\"<tr><td>\"+validation_performance_str+\"<//td><tr>\")\n",
    "            objOutputFile.write(\"<tr><td></td></tr>\")\n",
    "            objOutputFile.write(\"<tr><td></td></tr>\")\n",
    "            \n",
    "        #plot training loss and accurasies\n",
    "        plt.style.use('dark_background')\n",
    "        plt.figure(figsize=(15,6))\n",
    "        plt.subplot(121)\n",
    "        plt.plot(range(epochs), train_val_loss, label= \"Training loss\", color=\"orange\", linewidth=4,marker='o')\n",
    "        plt.plot(range(epochs), validation_val_loss, label= \"Validation loss\", color=\"green\", linewidth=4 ,linestyle='--', marker='o')\n",
    "        plt.legend()\n",
    "        plt.title (\"Loss performance for Training and Validation datasets\") \n",
    "        plt.xlabel(\"epoch\")\n",
    "        plt.ylabel(\"Loss value\")\n",
    "        plt.subplot(122)\n",
    "        plt.plot(range(epochs), train_val_acc, label= \"Training accuracies\", color= \"orange\", linewidth=4,marker='o')\n",
    "        plt.plot(range(epochs), validation_val_acc, label= \"Validation accuracies\", color= \"green\", linewidth=4,linestyle='--', marker='o')\n",
    "        plt.legend()\n",
    "        plt.title (\"Accuracy performance for Training and Validation datasets\") \n",
    "        plt.xlabel(\"epoch\")\n",
    "        plt.ylabel(\"Accuracy value\")\n",
    "        # Saving the chart to png file\n",
    "        pngfilename = outputfilename_sub+\"_graphs.png\"\n",
    "        plt.savefig(pngfilename)\n",
    "        #time.sleep(2)\n",
    "        # chart display\n",
    "        #plt.show (block=True)\n",
    "        plt.show\n",
    "\n",
    "        # embedding the chart png into the HTML file\n",
    "        pngfilename_1 = pngfilename.split(\"/\")[1]#\"Performance_graphs.png\"\n",
    "        performance_str = f\"------------- Accuracy and Loss Performance ------------- \"\n",
    "        objOutputFile.write(\"<tr><td>\"+performance_str+\"</td></tr>\")\n",
    "        objOutputFile.write(\"<tr><td></td></tr>\")\n",
    "        objOutputFile.write(\"<tr><td></td></tr>\")\n",
    "        objOutputFile.write(\"<tr><td><img src=\"+pngfilename_1+\"></img></td></tr>\")\n",
    "        objOutputFile.write(\"</table></body></html>\")              \n",
    "        objOutputFile.write(\"<tr><td></td></tr>\")\n",
    "        \n",
    "        # Predict the petrov type\n",
    "        CM_pngfilename = outputfilename_sub+\"_CM.png\"\n",
    "        # constant for classes\n",
    "        petrov_classes = ('O', 'I', 'II', 'III', 'D','N')\n",
    "        for X,Y in test_loader:\n",
    "            y_predicted = obj_model_petrov.determine_petrov(X.float())\n",
    "            \n",
    "            print (\"Pridicting the inout digit and checking the accuracy of prediction\")\n",
    "            print (\"Input digit: \")\n",
    "            print (Y)\n",
    "            print(\"Predicted digit: \")\n",
    "            print (y_predicted)\n",
    "            print(\"Accuracy of prediction: \")\n",
    "            print (Y==y_predicted)\n",
    "\n",
    "\n",
    "            # Build confusion matrix\n",
    "            cf_matrix = confusion_matrix(Y, y_predicted)\n",
    "            df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) *6, index = [i for i in petrov_classes],\n",
    "                                 columns = [i for i in petrov_classes])\n",
    "            plt.figure(figsize = (12,7))\n",
    "            sn.heatmap(df_cm, annot=True)\n",
    "            plt.xlabel('Predicted Class', fontsize = 15) \n",
    "            plt.ylabel('Actual class', fontsize = 15) \n",
    "            plt.savefig(CM_pngfilename)\n",
    "            plt.show\n",
    "\n",
    "            # embedding the heatmap chart png into the HTML file\n",
    "            CM_pngfilename_1 = CM_pngfilename.split(\"/\")[1]#\"Performance_CM.png\"\n",
    "            objOutputFile.write(\"<table>\")\n",
    "            CM_str = f\"------------- Confusion Matrix ------------- \"\n",
    "            objOutputFile.write(\"<tr><td>\"+CM_str+\"</td></tr>\")\n",
    "            objOutputFile.write(\"<tr><td></td></tr>\")\n",
    "            objOutputFile.write(\"<tr><td></td></tr>\")\n",
    "            objOutputFile.write(\"<tr><td><img src=\"+CM_pngfilename_1+\"></img></td></tr>\")\n",
    "            objOutputFile.write(\"</table></body></html>\")              \n",
    "            objOutputFile.close()\n",
    "            print(\"Report writing to output file \" + outputfilename + \" completed\")\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
