{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Satvik Varshney ; Waterloo ID: 20764052\n",
    "#### Phys 449 , Main Assignment\n",
    "#### Submission date : 06 Dec 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Necessary Libraries\n",
    "\n",
    "# Data read/write libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "\n",
    "# Data calculation and manipulation libraries\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#PyTorch Specific libraries\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "#plaotting the chart\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the petrov type determination Model \n",
    "class model_petrovtype_classification(nn.Module):\n",
    "    def __init__(self):   \n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_layer_1 = nn.Linear(num_input, num_hidden)  # 5,500\n",
    "        self.hidden_layer_2 = nn.Linear(num_hidden, num_hidden)   # 500,500\n",
    "        self.hidden_layer_3 = nn.Linear(num_hidden, num_hidden)   # 500,500\n",
    "        self.hidden_layer_4 = nn.Linear(num_hidden, num_hidden)   # 500,500\n",
    "        self.output_layer = nn.Linear(num_hidden, num_classes)   # 500, 6\n",
    "\n",
    "        # Reset the layers\n",
    "        self.hidden_layer_1.reset_parameters()\n",
    "        self.hidden_layer_2.reset_parameters()\n",
    "        self.hidden_layer_3.reset_parameters()\n",
    "        self.hidden_layer_4.reset_parameters()\n",
    "        self.output_layer.reset_parameters()\n",
    "        \n",
    "        self.activation_layer1 = nn.Tanh()\n",
    "        self.dropout_layer1 = nn.Dropout(p=0.2)\n",
    "        self.activation_layer2 = nn.Sigmoid()\n",
    "        self.dropout_layer2 = nn.Dropout(p=0.2)\n",
    "        self.activation_layer3 = nn.Tanh()\n",
    "        self.dropout_layer3 = nn.Dropout(p=0.2)\n",
    "        self.activation_layer4 = nn.Sigmoid()\n",
    "        self.dropout_layer4 = nn.Dropout(p=0.2)\n",
    "        self.activation_outputlayer = nn.Softmax(dim=1)\n",
    "\n",
    "        self.loss = nn.CrossEntropyLoss() # Loss used for multi variate analysis\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.hidden_layer_1(inputs)\n",
    "        x = self.activation_layer1(x)\n",
    "        x = self.dropout_layer1(x)\n",
    "        x = self.hidden_layer_2(x)\n",
    "        x = self.activation_layer2(x)\n",
    "        x = self.dropout_layer2(x)\n",
    "        x = self.hidden_layer_3(x)\n",
    "        x = self.activation_layer3(x)\n",
    "        x = self.dropout_layer3(x)\n",
    "        x = self.hidden_layer_4(x)\n",
    "        x = self.activation_layer4(x)\n",
    "        x = self.dropout_layer4(x)\n",
    "        x = self.output_layer(x)\n",
    "        x = self.activation_outputlayer(x)\n",
    "        return x\n",
    "\n",
    "    def fit(self, X,Y):\n",
    "        self.optimizer.zero_grad()\n",
    "        y_pred = self.forward(X)\n",
    "        loss = self.loss(y_pred, Y)\n",
    "        y_pred_max = torch.argmax(y_pred, axis=1)\n",
    "        train_accuracy = (Y == y_pred_max).sum()\n",
    "        loss.backward()   #backpropagation\n",
    "        self.optimizer.step()   # updating the weights\n",
    "        return loss.item(), train_accuracy\n",
    "\n",
    "    def evaluate(self,test_dataloader):\n",
    "        acc_test = 0\n",
    "        loss_test= 0\n",
    "        for X,Y in test_dataloader:\n",
    "            with torch.no_grad():\n",
    "                loss_temp = self.loss(self.forward(X.float()), Y.long())\n",
    "                # just to manage the error relted to numpy and tensor\n",
    "                loss_temp = loss_temp.detach().numpy()\n",
    "                loss_test += loss_temp\n",
    "                # to calculate the test accuracy\n",
    "                y_pred_test = torch.argmax(self.forward(X.float()), axis=1)\n",
    "                acc_test += (Y == y_pred_test).sum()   # batch\n",
    "\n",
    "        avg_acc_test = acc_test / (len(test_dataloader)* batch)\n",
    "        avg_loss_test = loss_test/len(test_dataloader)\n",
    "\n",
    "        return avg_acc_test ,avg_loss_test\n",
    "    \n",
    "    def determine_petrov(self,X):\n",
    "        with torch.no_grad():\n",
    "            y_pred_test= self.forward(X)\n",
    "            return torch.argmax(y_pred_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class class_data_tranformation:\n",
    "    def fn_convert_petrov_classification_data(self, y):\n",
    "        y_converted = []\n",
    "        for idx, y_val in enumerate(y):\n",
    "            if y_val == \"O\": y_converted.append(0)\n",
    "            elif y_val == \"I\": y_converted.append(1)\n",
    "            elif y_val == \"II\": y_converted.append(2)\n",
    "            elif y_val == \"III\": y_converted.append(3)\n",
    "            elif y_val == \"D\": y_converted.append(4)\n",
    "            elif y_val == \"N\": y_converted.append(5)\n",
    "        return y_converted\n",
    "\n",
    "    def fn_split_train_val_test(self, data):\n",
    "        # separate the last colums as y-data\n",
    "        Y = data[:,5] \n",
    "        X = np.delete(data, 5,1)  # Input data\n",
    "        y = np.array(self.fn_convert_petrov_classification_data(Y))\n",
    "        total_rows, total_cols = data.shape\n",
    "        testdata_rows = int(total_rows*30/100) # 30% test data\n",
    "        # separate the test data Last 30% records\n",
    "        x_test_temp = X[-testdata_rows:, :]\n",
    "        y_test_temp = y[-testdata_rows:]\n",
    "\n",
    "        # build the training data 70%\n",
    "        x_train  = X[:-len(x_test_temp), :] \n",
    "        y_train = y[:-len(y_test_temp)] \n",
    "\n",
    "        # separate 15% as validation data from Test data 15%\n",
    "        x_test = x_test_temp[-int(testdata_rows/2):, :]\n",
    "        y_test = y_test_temp[-int(testdata_rows/2):]\n",
    "\n",
    "        # build the validartion data 15%\n",
    "        x_val  = x_test_temp[:-len(x_test), :] \n",
    "        y_val = y_test_temp[:-len(y_test)] \n",
    "\n",
    "        # change the dtype to 'float64'\n",
    "        x_train = x_train.astype('float64')\n",
    "        x_test = x_test.astype('float64')  \n",
    "        x_val = x_val.astype('float64')   \n",
    "\n",
    "        return x_train, y_train, x_val, y_val, x_test, y_test\n",
    "    \n",
    "    def fn_convert_pertov_data(self,x):\n",
    "        idx = np.nonzero(x)\n",
    "        x[idx[0], idx[1]] = 1\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 0:   1%|▎                                                             | 11/2081 [00:00<00:19, 105.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train unnormalized =  [[  0.   0.   0.   0.   0.]\n",
      " [ -9.   0.   3. -10.   0.]\n",
      " [  0.   0.   0.   3.  -6.]]\n",
      "x_train normalized =  [[0.5  0.5  0.5  0.5  0.5 ]\n",
      " [0.05 0.5  0.65 0.   0.5 ]\n",
      " [0.5  0.5  0.5  0.65 0.2 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 0: 100%|████████████████████████████████████████████████████████████| 2081/2081 [00:17<00:00, 122.25it/s]\n",
      "Fitting epoch 1:   1%|▎                                                             | 11/2081 [00:00<00:19, 103.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training Loss = : 1.6944 and Accuracy = : 0.3308\n",
      "Epoch 1 Validation Loss = : 1.6935 and Accuracy = : 0.3309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 1: 100%|████████████████████████████████████████████████████████████| 2081/2081 [00:18<00:00, 114.06it/s]\n",
      "Fitting epoch 2:   1%|▎                                                             | 11/2081 [00:00<00:20, 101.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training Loss = : 1.6345 and Accuracy = : 0.3956\n",
      "Epoch 2 Validation Loss = : 1.4356 and Accuracy = : 0.6080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 2: 100%|████████████████████████████████████████████████████████████| 2081/2081 [00:18<00:00, 109.88it/s]\n",
      "Fitting epoch 3:   0%|▎                                                              | 10/2081 [00:00<00:21, 96.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training Loss = : 1.3600 and Accuracy = : 0.6831\n",
      "Epoch 3 Validation Loss = : 1.3066 and Accuracy = : 0.7353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 3: 100%|████████████████████████████████████████████████████████████| 2081/2081 [00:19<00:00, 108.16it/s]\n",
      "Fitting epoch 4:   1%|▎                                                             | 11/2081 [00:00<00:20, 102.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training Loss = : 1.1832 and Accuracy = : 0.8590\n",
      "Epoch 4 Validation Loss = : 1.1484 and Accuracy = : 0.8934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 4: 100%|████████████████████████████████████████████████████████████| 2081/2081 [00:19<00:00, 106.81it/s]\n",
      "Fitting epoch 5:   0%|▎                                                              | 10/2081 [00:00<00:21, 97.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training Loss = : 1.1142 and Accuracy = : 0.9285\n",
      "Epoch 5 Validation Loss = : 1.0821 and Accuracy = : 0.9605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 5: 100%|████████████████████████████████████████████████████████████| 2081/2081 [00:19<00:00, 105.84it/s]\n",
      "Fitting epoch 6:   0%|▎                                                              | 10/2081 [00:00<00:21, 98.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training Loss = : 1.0736 and Accuracy = : 0.9700\n",
      "Epoch 6 Validation Loss = : 1.0737 and Accuracy = : 0.9713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 6: 100%|████████████████████████████████████████████████████████████| 2081/2081 [00:19<00:00, 104.78it/s]\n",
      "Fitting epoch 7:   1%|▌                                                              | 20/2081 [00:00<00:22, 92.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training Loss = : 1.0704 and Accuracy = : 0.9730\n",
      "Epoch 7 Validation Loss = : 1.0676 and Accuracy = : 0.9763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 7: 100%|████████████████████████████████████████████████████████████| 2081/2081 [00:20<00:00, 103.11it/s]\n",
      "Fitting epoch 8:   0%|▎                                                               | 9/2081 [00:00<00:24, 83.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training Loss = : 1.0694 and Accuracy = : 0.9740\n",
      "Epoch 8 Validation Loss = : 1.0676 and Accuracy = : 0.9762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 8: 100%|████████████████████████████████████████████████████████████| 2081/2081 [00:20<00:00, 101.95it/s]\n",
      "Fitting epoch 9:   0%|▎                                                              | 10/2081 [00:00<00:21, 97.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Training Loss = : 1.0679 and Accuracy = : 0.9755\n",
      "Epoch 9 Validation Loss = : 1.0658 and Accuracy = : 0.9764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 9: 100%|█████████████████████████████████████████████████████████████| 2081/2081 [00:21<00:00, 96.60it/s]\n",
      "Fitting epoch 10:   0%|▏                                                              | 8/2081 [00:00<00:25, 79.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Training Loss = : 1.0671 and Accuracy = : 0.9761\n",
      "Epoch 10 Validation Loss = : 1.0665 and Accuracy = : 0.9772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 10: 100%|████████████████████████████████████████████████████████████| 2081/2081 [00:21<00:00, 97.03it/s]\n",
      "Fitting epoch 11:   0%|▎                                                             | 10/2081 [00:00<00:22, 91.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Training Loss = : 1.0660 and Accuracy = : 0.9774\n",
      "Epoch 11 Validation Loss = : 1.0611 and Accuracy = : 0.9822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 11: 100%|████████████████████████████████████████████████████████████| 2081/2081 [00:21<00:00, 96.04it/s]\n",
      "Fitting epoch 12:   0%|▎                                                             | 10/2081 [00:00<00:22, 90.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Training Loss = : 1.0650 and Accuracy = : 0.9783\n",
      "Epoch 12 Validation Loss = : 1.0698 and Accuracy = : 0.9731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 12: 100%|████████████████████████████████████████████████████████████| 2081/2081 [00:23<00:00, 87.62it/s]\n",
      "Fitting epoch 13:   0%|▏                                                              | 8/2081 [00:00<00:26, 77.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Training Loss = : 1.0643 and Accuracy = : 0.9790\n",
      "Epoch 13 Validation Loss = : 1.0614 and Accuracy = : 0.9819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 13: 100%|████████████████████████████████████████████████████████████| 2081/2081 [00:24<00:00, 86.05it/s]\n",
      "Fitting epoch 14:   0%|▎                                                              | 9/2081 [00:00<00:25, 82.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Training Loss = : 1.0643 and Accuracy = : 0.9791\n",
      "Epoch 14 Validation Loss = : 1.0638 and Accuracy = : 0.9796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 14: 100%|████████████████████████████████████████████████████████████| 2081/2081 [00:23<00:00, 89.81it/s]\n",
      "Fitting epoch 15:   0%|▎                                                              | 9/2081 [00:00<00:24, 85.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Training Loss = : 1.0627 and Accuracy = : 0.9806\n",
      "Epoch 15 Validation Loss = : 1.0664 and Accuracy = : 0.9776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 15: 100%|████████████████████████████████████████████████████████████| 2081/2081 [00:22<00:00, 92.60it/s]\n",
      "Fitting epoch 16:   0%|▎                                                              | 9/2081 [00:00<00:23, 86.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Training Loss = : 1.0627 and Accuracy = : 0.9805\n",
      "Epoch 16 Validation Loss = : 1.0654 and Accuracy = : 0.9784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 16: 100%|████████████████████████████████████████████████████████████| 2081/2081 [00:22<00:00, 93.61it/s]\n",
      "Fitting epoch 17:   1%|▌                                                             | 17/2081 [00:00<00:26, 79.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Training Loss = : 1.0619 and Accuracy = : 0.9813\n",
      "Epoch 17 Validation Loss = : 1.0976 and Accuracy = : 0.9454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 17: 100%|████████████████████████████████████████████████████████████| 2081/2081 [00:22<00:00, 92.12it/s]\n",
      "Fitting epoch 18:   1%|▌                                                             | 18/2081 [00:00<00:24, 83.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Training Loss = : 1.0617 and Accuracy = : 0.9816\n",
      "Epoch 18 Validation Loss = : 1.0656 and Accuracy = : 0.9772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 18: 100%|████████████████████████████████████████████████████████████| 2081/2081 [00:22<00:00, 91.79it/s]\n",
      "Fitting epoch 19:   0%|▎                                                              | 9/2081 [00:00<00:24, 83.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Training Loss = : 1.0620 and Accuracy = : 0.9813\n",
      "Epoch 19 Validation Loss = : 1.0727 and Accuracy = : 0.9711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 19: 100%|████████████████████████████████████████████████████████████| 2081/2081 [00:23<00:00, 89.43it/s]\n",
      "Fitting epoch 20:   0%|▎                                                              | 9/2081 [00:00<00:24, 85.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Training Loss = : 1.0611 and Accuracy = : 0.9822\n",
      "Epoch 20 Validation Loss = : 1.0692 and Accuracy = : 0.9735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 20: 100%|████████████████████████████████████████████████████████████| 2081/2081 [00:23<00:00, 88.95it/s]\n",
      "Fitting epoch 21:   0%|▏                                                              | 8/2081 [00:00<00:27, 75.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Training Loss = : 1.0600 and Accuracy = : 0.9833\n",
      "Epoch 21 Validation Loss = : 1.0567 and Accuracy = : 0.9862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 21: 100%|████████████████████████████████████████████████████████████| 2081/2081 [00:23<00:00, 87.45it/s]\n",
      "Fitting epoch 22:   0%|▏                                                              | 8/2081 [00:00<00:26, 78.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Training Loss = : 1.0602 and Accuracy = : 0.9831\n",
      "Epoch 22 Validation Loss = : 1.0589 and Accuracy = : 0.9837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 22: 100%|████████████████████████████████████████████████████████████| 2081/2081 [00:23<00:00, 87.49it/s]\n",
      "Fitting epoch 23:   1%|▌                                                             | 17/2081 [00:00<00:26, 78.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Training Loss = : 1.0608 and Accuracy = : 0.9825\n",
      "Epoch 23 Validation Loss = : 1.0585 and Accuracy = : 0.9851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 23: 100%|████████████████████████████████████████████████████████████| 2081/2081 [00:24<00:00, 85.89it/s]\n",
      "Fitting epoch 24:   0%|▏                                                              | 8/2081 [00:00<00:27, 76.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Training Loss = : 1.0603 and Accuracy = : 0.9830\n",
      "Epoch 24 Validation Loss = : 1.0615 and Accuracy = : 0.9817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 24: 100%|████████████████████████████████████████████████████████████| 2081/2081 [00:24<00:00, 84.85it/s]\n",
      "Fitting epoch 25:   0%|▏                                                              | 8/2081 [00:00<00:26, 77.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Training Loss = : 1.0595 and Accuracy = : 0.9837\n",
      "Epoch 25 Validation Loss = : 1.0592 and Accuracy = : 0.9843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 25: 100%|████████████████████████████████████████████████████████████| 2081/2081 [00:24<00:00, 83.97it/s]\n",
      "Fitting epoch 26:   0%|▏                                                              | 7/2081 [00:00<00:30, 69.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Training Loss = : 1.0586 and Accuracy = : 0.9847\n",
      "Epoch 26 Validation Loss = : 1.0653 and Accuracy = : 0.9773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 26: 100%|████████████████████████████████████████████████████████████| 2081/2081 [00:24<00:00, 83.27it/s]\n",
      "Fitting epoch 27:   0%|▏                                                              | 8/2081 [00:00<00:28, 72.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Training Loss = : 1.0601 and Accuracy = : 0.9832\n",
      "Epoch 27 Validation Loss = : 1.0606 and Accuracy = : 0.9820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 27: 100%|████████████████████████████████████████████████████████████| 2081/2081 [00:25<00:00, 80.13it/s]\n",
      "Fitting epoch 28:   0%|▏                                                              | 8/2081 [00:00<00:27, 74.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Training Loss = : 1.0591 and Accuracy = : 0.9842\n",
      "Epoch 28 Validation Loss = : 1.0571 and Accuracy = : 0.9860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting epoch 28:  32%|███████████████████▋                                         | 671/2081 [00:08<00:17, 81.48it/s]"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    if sys.argv[1] == \"--help\":\n",
    "        print (\"Syntax = python main.py param/param_file_name.json petrov_data.csv performance.html\")\n",
    "        print (\"Parameter 1 = param/param_file_name.json \")\n",
    "        print (\"  Parameter 1 description = JSON file to keep the hyper parameters (e.g. learning rate, batch size, etc.)\")\n",
    "        print (\"  Parameter 1 default value = param/param_file_name.json\")\n",
    "        print (\"  Parameter 1 file type = JSON\")\n",
    "        print (\"Parameter 2 = even_mnist.csv \")\n",
    "        print (\"  Parameter 2 description = Petrov Input dataset file name with path\")\n",
    "        print (\"  Parameter 2 default value = even_mnist.csv\")\n",
    "        print (\"  Parameter 2 file type = csv\")\n",
    "        print (\"Parameter 3 = performance.html \")\n",
    "        print (\"  Parameter 3 description = html file name with path to record the output.This report summarizes the final results and performance.\")\n",
    "        print (\"  Parameter 3 default value = result/Performance.html\")\n",
    "        print (\"  Parameter 3 file type = html\")\n",
    "    else:\n",
    "        if len(sys.argv) == 4: \n",
    "            json_file = sys.argv[1] #param/param_file_name.json\n",
    "            dataset_url = sys.argv[2] #'even_mnist.csv'\n",
    "            outputfilename = sys.argv[3] # performance.html\n",
    "        else:\n",
    "            json_file = \"param/param_file_name.json\" \n",
    "            dataset_url = \"petrov_data.csv\"\n",
    "            outputfilename = \"result/Performance.html\"\n",
    "            \n",
    "        obj_dt = class_data_tranformation()\n",
    "        # reading csv file\n",
    "        df = pd.read_csv(dataset_url, sep=',', header=None)\n",
    "        data = df.to_numpy() # convert dataframe to array\n",
    "        x_train, y_train, x_val, y_val, x_test, y_test  = obj_dt.fn_split_train_val_test(data)\n",
    "\n",
    "        # Importing json file to read the parametes\n",
    "        f = open(json_file)\n",
    "        dt_json = json.load(f)\n",
    "        lr = dt_json['learning rate']\n",
    "        # specify input dimensions of each image\n",
    "        num_input = dt_json['num_input'] #5\n",
    "        # batch size, number of classes, epochs\n",
    "        batch = dt_json['batch_size']#128\n",
    "        num_classes = dt_json['num_classes']#6\n",
    "        epochs = dt_json['num iter']\n",
    "        num_hidden = dt_json['num_hidden']\n",
    "\n",
    "        # normalise datasets\n",
    "        x_train = (x_train - x_train.min()) / (x_train.max() - x_train.min())\n",
    "        x_test = (x_test - x_test.min()) / (x_test.max() - x_test.min())\n",
    "        x_val = (x_val - x_val.min()) / (x_val.max() - x_val.min())\n",
    "        \n",
    "#        x_train = obj_dt.fn_convert_pertov_data(x_train)\n",
    "#        x_test = obj_dt.fn_convert_pertov_data(x_test)\n",
    "#        x_val = obj_dt.fn_convert_pertov_data(x_val)\n",
    "        #Converting to Tensors\n",
    "        X_train = torch.from_numpy(x_train)\n",
    "        X_test = torch.from_numpy(x_test)\n",
    "        X_val = torch.from_numpy(x_val)\n",
    "\n",
    "        y_train = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "        y_test = torch.from_numpy(y_test).type(torch.LongTensor)\n",
    "        y_val = torch.from_numpy(y_val).type(torch.LongTensor)\n",
    "\n",
    "        train = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "        test = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "        val = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "        # Set our data loaders into batches\n",
    "        train_loader = torch.utils.data.DataLoader(train, batch_size = batch, shuffle = True)\n",
    "        test_loader = torch.utils.data.DataLoader(test, batch_size = batch, shuffle = True)\n",
    "        val_loader = torch.utils.data.DataLoader(val, batch_size = batch, shuffle = True)\n",
    "\n",
    "        # Open output html file \n",
    "        outputfilename_sub = outputfilename[:len(outputfilename)-5]\n",
    "        objOutputFile = open(outputfilename,\"w\")\n",
    "        # Adding header data to the HTML file\n",
    "#        objOutputFile.write(\"<html>\\n<head><title bgcolor='#2980B9'> \\nPerformance Report \\</title></head> <body><h1>Physics 449 Main Assignment</h1><h2>Satvik Varshney</h2></body></html>\")\n",
    "        objOutputFile.write(\"<html>\\n<head><title bgcolor='#2980B9'> \\nPerformance Report \\</title></head> <body><h1>Physics 449 Main Assignment</h1></body></html>\")\n",
    "        objOutputFile.write(\"<table>\")\n",
    "        \n",
    "        #Building the Model\n",
    "        obj_model_petrov = model_petrovtype_classification().to(torch.device(\"cpu\"))\n",
    "\n",
    "        # Initialize the vectors for performance tracking and display for train and test dataset\n",
    "        train_val_loss = []\n",
    "        train_val_acc = []\n",
    "        validation_val_loss = []\n",
    "        validation_val_acc=[]\n",
    "\n",
    "        for i in range(epochs):\n",
    "            # Train the system\n",
    "            total_loss = 0\n",
    "            total_acc = 0\n",
    "            for X,Y in tqdm(train_loader, desc = f\"Fitting epoch {i}\"):\n",
    "                loss, acc = obj_model_petrov.fit(X.float(),Y.long())\n",
    "                total_loss += loss\n",
    "                total_acc +=acc\n",
    "            avg_loss = total_loss/len(train_loader)\n",
    "            avg_acc = total_acc / (len(train_loader)* batch)\n",
    "            train_val_loss.append(avg_loss)\n",
    "            train_val_acc.append(avg_acc)\n",
    "            # Evaluate the model\n",
    "            acc_test,loss_test = obj_model_petrov.evaluate(val_loader)\n",
    "            validation_val_loss.append(loss_test)\n",
    "            validation_val_acc.append(acc_test)\n",
    "            # Training, test data loss and accuray recording\n",
    "            training_performance_str = f\"Epoch {i+1} Training Loss = : {avg_loss:.4f} and Accuracy = : {avg_acc:.4f}\"\n",
    "            validation_performance_str = f\"Epoch {i+1} Validation Loss = : {loss_test:.4f} and Accuracy = : {acc_test:.4f}\"\n",
    "            # Pring Training and test data loss, accuray information to screen\n",
    "            print(training_performance_str)\n",
    "            print(validation_performance_str)\n",
    "            # Write Training and test data loss, accuray information to output html file\n",
    "            objOutputFile.write(\"<tr><td>\"+training_performance_str+\"</td></tr>\")\n",
    "            objOutputFile.write(\"<tr><td>\"+validation_performance_str+\"<//td><tr>\")\n",
    "            objOutputFile.write(\"<tr><td></td></tr>\")\n",
    "            objOutputFile.write(\"<tr><td></td></tr>\")\n",
    "            \n",
    "        #plot training loss and accurasies\n",
    "        plt.style.use('dark_background')\n",
    "        plt.figure(figsize=(15,6))\n",
    "        plt.subplot(121)\n",
    "        plt.plot(range(epochs), train_val_loss, label= \"Training loss\", color=\"orange\", linewidth=4,marker='o')\n",
    "        plt.plot(range(epochs), validation_val_loss, label= \"Validation loss\", color=\"green\", linewidth=4 ,linestyle='--', marker='o')\n",
    "        plt.legend()\n",
    "        plt.title (\"Loss performance for Training and Validation datasets\") \n",
    "        plt.xlabel(\"epoch\")\n",
    "        plt.ylabel(\"Loss value\")\n",
    "        plt.subplot(122)\n",
    "        plt.plot(range(epochs), train_val_acc, label= \"Training accuracies\", color= \"orange\", linewidth=4,marker='o')\n",
    "        plt.plot(range(epochs), validation_val_acc, label= \"Validation accuracies\", color= \"green\", linewidth=4,linestyle='--', marker='o')\n",
    "        plt.legend()\n",
    "        plt.title (\"Accuracy performance for Training and Validation datasets\") \n",
    "        plt.xlabel(\"epoch\")\n",
    "        plt.ylabel(\"Accuracy value\")\n",
    "        # Saving the chart to png file\n",
    "        pngfilename = outputfilename_sub+\"_graphs.png\"\n",
    "        plt.savefig(pngfilename)\n",
    "        #time.sleep(2)\n",
    "        # chart display\n",
    "        #plt.show (block=True)\n",
    "        plt.show\n",
    "\n",
    "        # embedding the chart png into the HTML file\n",
    "        pngfilename_1 = pngfilename.split(\"/\")[1]#\"Performance_graphs.png\"\n",
    "        performance_str = f\"------------- Accuracy and Loss Performance ------------- \"\n",
    "        objOutputFile.write(\"<tr><td>\"+performance_str+\"</td></tr>\")\n",
    "        objOutputFile.write(\"<tr><td></td></tr>\")\n",
    "        objOutputFile.write(\"<tr><td></td></tr>\")\n",
    "        objOutputFile.write(\"<tr><td><img src=\"+pngfilename_1+\"></img></td></tr>\")\n",
    "        objOutputFile.write(\"</table></body></html>\")              \n",
    "        objOutputFile.write(\"<tr><td></td></tr>\")\n",
    "        \n",
    "        # Predict the petrov type\n",
    "        CM_pngfilename = outputfilename_sub+\"_CM.png\"\n",
    "        # constant for classes\n",
    "        petrov_classes = ('O', 'I', 'II', 'III', 'D','N')\n",
    "        for X,Y in test_loader:\n",
    "            y_predicted = obj_model_petrov.determine_petrov(X.float())\n",
    "            \n",
    "            print (\"Pridicting the inout digit and checking the accuracy of prediction\")\n",
    "            print (\"Input digit: \")\n",
    "            print (Y)\n",
    "            print(\"Predicted digit: \")\n",
    "            print (y_predicted)\n",
    "            print(\"Accuracy of prediction: \")\n",
    "            print (Y==y_predicted)\n",
    "\n",
    "\n",
    "            # Build confusion matrix\n",
    "            cf_matrix = confusion_matrix(Y, y_predicted)\n",
    "            df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) *6, index = [i for i in petrov_classes],\n",
    "                                 columns = [i for i in petrov_classes])\n",
    "            plt.figure(figsize = (12,7))\n",
    "            sn.heatmap(df_cm, annot=True)\n",
    "            plt.xlabel('Predicted Class', fontsize = 15) \n",
    "            plt.ylabel('Actual class', fontsize = 15) \n",
    "            plt.savefig(CM_pngfilename)\n",
    "            plt.show\n",
    "\n",
    "            # embedding the heatmap chart png into the HTML file\n",
    "            CM_pngfilename_1 = CM_pngfilename.split(\"/\")[1]#\"Performance_CM.png\"\n",
    "            objOutputFile.write(\"<table>\")\n",
    "            CM_str = f\"------------- Confusion Matrix ------------- \"\n",
    "            objOutputFile.write(\"<tr><td>\"+CM_str+\"</td></tr>\")\n",
    "            objOutputFile.write(\"<tr><td></td></tr>\")\n",
    "            objOutputFile.write(\"<tr><td></td></tr>\")\n",
    "            objOutputFile.write(\"<tr><td><img src=\"+CM_pngfilename_1+\"></img></td></tr>\")\n",
    "            objOutputFile.write(\"</table></body></html>\")              \n",
    "            objOutputFile.close()\n",
    "            print(\"Report writing to output file \" + outputfilename + \" completed\")\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
